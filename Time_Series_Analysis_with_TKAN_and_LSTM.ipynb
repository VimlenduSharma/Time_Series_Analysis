{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1df8a076-1141-4dc0-830d-c590f405404b",
   "metadata": {},
   "source": [
    "#importing_necessary_libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f3d0721-cb3c-49e0-9619-b09ced91e3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tkan\n",
      "  Downloading tkan-0.4.3-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: keras<4.0.0,>=3.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tkan) (3.5.0)\n",
      "Collecting keras_efficient_kan<0.2.0,>=0.1.9 (from tkan)\n",
      "  Downloading keras_efficient_kan-0.1.9-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.12/site-packages (from keras<4.0.0,>=3.0.0->tkan) (2.1.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from keras<4.0.0,>=3.0.0->tkan) (1.26.4)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras<4.0.0,>=3.0.0->tkan) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras<4.0.0,>=3.0.0->tkan) (0.0.8)\n",
      "Requirement already satisfied: h5py in /opt/anaconda3/lib/python3.12/site-packages (from keras<4.0.0,>=3.0.0->tkan) (3.11.0)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras<4.0.0,>=3.0.0->tkan) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in /opt/anaconda3/lib/python3.12/site-packages (from keras<4.0.0,>=3.0.0->tkan) (0.4.1)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from keras<4.0.0,>=3.0.0->tkan) (23.2)\n",
      "Collecting numpy (from keras<4.0.0,>=3.0.0->tkan)\n",
      "  Downloading numpy-2.0.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from optree->keras<4.0.0,>=3.0.0->tkan) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras<4.0.0,>=3.0.0->tkan) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras<4.0.0,>=3.0.0->tkan) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras<4.0.0,>=3.0.0->tkan) (0.1.0)\n",
      "Downloading tkan-0.4.3-py3-none-any.whl (7.4 kB)\n",
      "Downloading keras_efficient_kan-0.1.9-py3-none-any.whl (3.5 kB)\n",
      "Downloading numpy-2.0.0-cp312-cp312-macosx_14_0_arm64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, keras_efficient_kan, tkan\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "contourpy 1.2.0 requires numpy<2.0,>=1.20, but you have numpy 2.0.0 which is incompatible.\n",
      "tensorflow 2.17.0 requires numpy<2.0.0,>=1.26.0; python_version >= \"3.12\", but you have numpy 2.0.0 which is incompatible.\n",
      "streamlit 1.32.0 requires numpy<2,>=1.19.3, but you have numpy 2.0.0 which is incompatible.\n",
      "numba 0.59.1 requires numpy<1.27,>=1.22, but you have numpy 2.0.0 which is incompatible.\n",
      "pywavelets 1.5.0 requires numpy<2.0,>=1.22.4, but you have numpy 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras_efficient_kan-0.1.9 numpy-2.0.0 tkan-0.4.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install tkan\n",
    "from tkan import TKAN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cc340eb-163f-4019-8af5-f96ede3dee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "seed=42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "191f8699-6aeb-4643-9ca4-fd1bc96bd166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Último</th>\n",
       "      <th>Apertura</th>\n",
       "      <th>Máximo</th>\n",
       "      <th>Mínimo</th>\n",
       "      <th>Vol.</th>\n",
       "      <th>% var.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>05.11.2024</td>\n",
       "      <td>5.782,76</td>\n",
       "      <td>5.722,43</td>\n",
       "      <td>5.783,44</td>\n",
       "      <td>5.722,10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1,23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04.11.2024</td>\n",
       "      <td>5.712,69</td>\n",
       "      <td>5.725,15</td>\n",
       "      <td>5.741,43</td>\n",
       "      <td>5.696,51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0,28%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.11.2024</td>\n",
       "      <td>5.728,80</td>\n",
       "      <td>5.723,22</td>\n",
       "      <td>5.772,52</td>\n",
       "      <td>5.723,22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,41%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.10.2024</td>\n",
       "      <td>5.705,45</td>\n",
       "      <td>5.775,34</td>\n",
       "      <td>5.775,34</td>\n",
       "      <td>5.702,86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1,86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.10.2024</td>\n",
       "      <td>5.813,67</td>\n",
       "      <td>5.832,65</td>\n",
       "      <td>5.850,94</td>\n",
       "      <td>5.811,28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0,33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.10.2024</td>\n",
       "      <td>5.832,92</td>\n",
       "      <td>5.819,68</td>\n",
       "      <td>5.847,19</td>\n",
       "      <td>5.802,17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,16%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28.10.2024</td>\n",
       "      <td>5.823,52</td>\n",
       "      <td>5.833,93</td>\n",
       "      <td>5.842,92</td>\n",
       "      <td>5.823,08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,27%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25.10.2024</td>\n",
       "      <td>5.808,12</td>\n",
       "      <td>5.826,75</td>\n",
       "      <td>5.862,82</td>\n",
       "      <td>5.799,98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0,03%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24.10.2024</td>\n",
       "      <td>5.809,86</td>\n",
       "      <td>5.817,80</td>\n",
       "      <td>5.817,80</td>\n",
       "      <td>5.784,92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23.10.2024</td>\n",
       "      <td>5.797,42</td>\n",
       "      <td>5.834,50</td>\n",
       "      <td>5.834,85</td>\n",
       "      <td>5.762,41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0,92%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22.10.2024</td>\n",
       "      <td>5.851,20</td>\n",
       "      <td>5.832,70</td>\n",
       "      <td>5.863,04</td>\n",
       "      <td>5.821,17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0,05%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>21.10.2024</td>\n",
       "      <td>5.853,98</td>\n",
       "      <td>5.857,82</td>\n",
       "      <td>5.866,92</td>\n",
       "      <td>5.824,79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0,18%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18.10.2024</td>\n",
       "      <td>5.864,67</td>\n",
       "      <td>5.859,43</td>\n",
       "      <td>5.872,17</td>\n",
       "      <td>5.846,11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,40%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>17.10.2024</td>\n",
       "      <td>5.841,47</td>\n",
       "      <td>5.875,62</td>\n",
       "      <td>5.878,46</td>\n",
       "      <td>5.840,25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0,02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>16.10.2024</td>\n",
       "      <td>5.842,47</td>\n",
       "      <td>5.816,58</td>\n",
       "      <td>5.846,52</td>\n",
       "      <td>5.808,34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,47%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.10.2024</td>\n",
       "      <td>5.815,26</td>\n",
       "      <td>5.866,74</td>\n",
       "      <td>5.870,36</td>\n",
       "      <td>5.804,48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0,76%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.10.2024</td>\n",
       "      <td>5.859,85</td>\n",
       "      <td>5.829,81</td>\n",
       "      <td>5.871,41</td>\n",
       "      <td>5.829,57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11.10.2024</td>\n",
       "      <td>5.815,03</td>\n",
       "      <td>5.775,09</td>\n",
       "      <td>5.822,13</td>\n",
       "      <td>5.775,09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,61%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10.10.2024</td>\n",
       "      <td>5.780,05</td>\n",
       "      <td>5.778,36</td>\n",
       "      <td>5.795,03</td>\n",
       "      <td>5.764,76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0,21%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>09.10.2024</td>\n",
       "      <td>5.792,04</td>\n",
       "      <td>5.751,80</td>\n",
       "      <td>5.796,80</td>\n",
       "      <td>5.745,02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,71%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>08.10.2024</td>\n",
       "      <td>5.751,13</td>\n",
       "      <td>5.719,14</td>\n",
       "      <td>5.757,60</td>\n",
       "      <td>5.714,56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>07.10.2024</td>\n",
       "      <td>5.695,94</td>\n",
       "      <td>5.737,80</td>\n",
       "      <td>5.739,34</td>\n",
       "      <td>5.686,85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0,96%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Fecha    Último  Apertura    Máximo    Mínimo  Vol.  % var.\n",
       "0   05.11.2024  5.782,76  5.722,43  5.783,44  5.722,10   NaN   1,23%\n",
       "1   04.11.2024  5.712,69  5.725,15  5.741,43  5.696,51   NaN  -0,28%\n",
       "2   01.11.2024  5.728,80  5.723,22  5.772,52  5.723,22   NaN   0,41%\n",
       "3   31.10.2024  5.705,45  5.775,34  5.775,34  5.702,86   NaN  -1,86%\n",
       "4   30.10.2024  5.813,67  5.832,65  5.850,94  5.811,28   NaN  -0,33%\n",
       "5   29.10.2024  5.832,92  5.819,68  5.847,19  5.802,17   NaN   0,16%\n",
       "6   28.10.2024  5.823,52  5.833,93  5.842,92  5.823,08   NaN   0,27%\n",
       "7   25.10.2024  5.808,12  5.826,75  5.862,82  5.799,98   NaN  -0,03%\n",
       "8   24.10.2024  5.809,86  5.817,80  5.817,80  5.784,92   NaN   0,21%\n",
       "9   23.10.2024  5.797,42  5.834,50  5.834,85  5.762,41   NaN  -0,92%\n",
       "10  22.10.2024  5.851,20  5.832,70  5.863,04  5.821,17   NaN  -0,05%\n",
       "11  21.10.2024  5.853,98  5.857,82  5.866,92  5.824,79   NaN  -0,18%\n",
       "12  18.10.2024  5.864,67  5.859,43  5.872,17  5.846,11   NaN   0,40%\n",
       "13  17.10.2024  5.841,47  5.875,62  5.878,46  5.840,25   NaN  -0,02%\n",
       "14  16.10.2024  5.842,47  5.816,58  5.846,52  5.808,34   NaN   0,47%\n",
       "15  15.10.2024  5.815,26  5.866,74  5.870,36  5.804,48   NaN  -0,76%\n",
       "16  14.10.2024  5.859,85  5.829,81  5.871,41  5.829,57   NaN   0,77%\n",
       "17  11.10.2024  5.815,03  5.775,09  5.822,13  5.775,09   NaN   0,61%\n",
       "18  10.10.2024  5.780,05  5.778,36  5.795,03  5.764,76   NaN  -0,21%\n",
       "19  09.10.2024  5.792,04  5.751,80  5.796,80  5.745,02   NaN   0,71%\n",
       "20  08.10.2024  5.751,13  5.719,14  5.757,60  5.714,56   NaN   0,97%\n",
       "21  07.10.2024  5.695,94  5.737,80  5.739,34  5.686,85   NaN  -0,96%"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('Datos históricos del S&P 500.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c0b0052-e039-4ce2-9ac9-d56a544a4272",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Último']=data['Último'].apply(lambda x:float(str(x).replace(',' , ''))*1000)\n",
    "data['Fecha']=pd.to_datetime(data['Fecha'], format=\"%d.%m.%Y\")\n",
    "data=data.sort_values(by='Fecha', ascending=True).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf4f2395-203c-42fd-93d7-16404b2b8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_series=data['Último'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce80c8-017f-4676-9811-51437b0b5c22",
   "metadata": {},
   "source": [
    "#Data_Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cdddd81-c221-45da-8793-4cf7b5da03cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()\n",
    "data_series_scaled=scaler.fit_transform(data_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "789e43ac-571d-400b-9fd1-0a8226f5b119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.32709062],\n",
       "       [0.56954898],\n",
       "       [0.49848871],\n",
       "       [0.70580217],\n",
       "       [0.97143365],\n",
       "       [0.70716529],\n",
       "       [0.86842885],\n",
       "       [0.86250222],\n",
       "       [1.        ],\n",
       "       [0.93664434],\n",
       "       [0.92016832],\n",
       "       [0.60143424],\n",
       "       [0.6751615 ],\n",
       "       [0.66484917],\n",
       "       [0.75611924],\n",
       "       [0.81182955],\n",
       "       [0.69774195],\n",
       "       [0.05636224],\n",
       "       [0.19474901],\n",
       "       [0.09927102],\n",
       "       [0.51454987]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_series_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e9df727-2538-4077-abd2-1c986aa02692",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data_series_scaled = scaler.fit_transform(data_series)\n",
    "\n",
    "window_size = 5\n",
    "future_steps_list = [1, 2, 3, 5]\n",
    "results = []\n",
    "\n",
    "for future_steps in future_steps_list:\n",
    "    X, y = [], []\n",
    "    for i in range(len(data_series_scaled) - window_size - future_steps + 1):\n",
    "        X.append(data_series_scaled[i:i + window_size])\n",
    "        y.append(data_series_scaled[i + window_size:i + window_size + future_steps].flatten())\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "split_index = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "fechas_train = data['Fecha'].iloc[window_size:split_index + window_size].values\n",
    "fechas_test = data['Fecha'].iloc[split_index + window_size:split_index + window_size + len(y_test)].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e68d09e-f49e-4d2b-b773-b41d0bdfb8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ce310be6-df5f-4852-8a48-f302d0e3cd99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97143365, 0.70716529, 0.86842885, 0.86250222, 1.        ],\n",
       "       [0.70716529, 0.86842885, 0.86250222, 1.        , 0.93664434],\n",
       "       [0.86842885, 0.86250222, 1.        , 0.93664434, 0.92016832],\n",
       "       [0.86250222, 1.        , 0.93664434, 0.92016832, 0.60143424],\n",
       "       [1.        , 0.93664434, 0.92016832, 0.60143424, 0.6751615 ],\n",
       "       [0.93664434, 0.92016832, 0.60143424, 0.6751615 , 0.66484917],\n",
       "       [0.92016832, 0.60143424, 0.6751615 , 0.66484917, 0.75611924],\n",
       "       [0.60143424, 0.6751615 , 0.66484917, 0.75611924, 0.81182955],\n",
       "       [0.6751615 , 0.66484917, 0.75611924, 0.81182955, 0.69774195],\n",
       "       [0.66484917, 0.75611924, 0.81182955, 0.69774195, 0.05636224]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93ea9ce-c87b-4c61-8ead-9db4dc2ddd98",
   "metadata": {},
   "source": [
    "#Construction_and_training_of_TKAN_Model\n",
    "The TKAN model is built and trained using a sequential architecture with a TKAN layer followed by a dense layer to multiple \n",
    "future steps. Model is compiled with Adam optimiser and a mean squared error(MSE) loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1acee5b6-39bc-4cc0-8e95-de685923560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - loss: 1.3759 - val_loss: 0.7782\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.0142 - val_loss: 0.5395\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.7133 - val_loss: 0.3596\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4733 - val_loss: 0.2351\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2918 - val_loss: 0.1602\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1640 - val_loss: 0.1271\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0830 - val_loss: 0.1266\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0405 - val_loss: 0.1487\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0272 - val_loss: 0.1837\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0337 - val_loss: 0.2232\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0514 - val_loss: 0.2604\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0734 - val_loss: 0.2907\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0946 - val_loss: 0.3115\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1116 - val_loss: 0.3218\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1228 - val_loss: 0.3222\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1279 - val_loss: 0.3138\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.1272 - val_loss: 0.2984\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1218 - val_loss: 0.2778\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1128 - val_loss: 0.2541\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1014 - val_loss: 0.2288\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0888 - val_loss: 0.2036\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0758 - val_loss: 0.1796\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0633 - val_loss: 0.1578\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0518 - val_loss: 0.1388\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0418 - val_loss: 0.1232\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0335 - val_loss: 0.1112\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0272 - val_loss: 0.1028\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0228 - val_loss: 0.0979\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0205 - val_loss: 0.0960\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0199 - val_loss: 0.0968\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0207 - val_loss: 0.0995\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0227 - val_loss: 0.1034\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0251 - val_loss: 0.1077\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0277 - val_loss: 0.1118\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0300 - val_loss: 0.1151\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0315 - val_loss: 0.1173\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0321 - val_loss: 0.1182\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0317 - val_loss: 0.1180\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0305 - val_loss: 0.1167\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0287 - val_loss: 0.1148\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0265 - val_loss: 0.1126\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0242 - val_loss: 0.1104\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0221 - val_loss: 0.1086\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0203 - val_loss: 0.1074\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0189 - val_loss: 0.1068\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0181 - val_loss: 0.1070\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0177 - val_loss: 0.1079\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0177 - val_loss: 0.1093\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0179 - val_loss: 0.1112\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0183 - val_loss: 0.1134\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step\n"
     ]
    }
   ],
   "source": [
    "model_tkan=Sequential([\n",
    "    TKAN(200, sub_kan_configs=[{'spline_order':4, 'grid_size':12}, {'spline_order':3, 'grid_size':10}, {'spline_order':5, 'grid_size':8}],\n",
    "         return_sequences=False, use_bias=True),\n",
    "    Dense(units=future_steps, activation='linear')\n",
    "])\n",
    "model_tkan.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "history_tkan=model_tkan.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n",
    "\n",
    "y_pred_tkan=model_tkan.predict(X_test)\n",
    "y_test_inverse=scaler.inverse_transform(y_test)\n",
    "y_pred_tkan_inverse=scaler.inverse_transform(y_pred_tkan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1043356-04df-404c-b93e-19ad698b11d3",
   "metadata": {},
   "source": [
    "#Construction_and_Training_of_LSTM_model\n",
    "is built and trained in similar way as TKAN , using an LSTM layer followed by a dense layer to predict multiple steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "62390289-bb99-40b3-8770-2cdbec03e60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533ms/step - loss: 0.6899 - val_loss: 0.4346\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.6411 - val_loss: 0.3923\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.5942 - val_loss: 0.3518\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.5485 - val_loss: 0.3126\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5036 - val_loss: 0.2744\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.4590 - val_loss: 0.2370\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4143 - val_loss: 0.2003\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3693 - val_loss: 0.1648\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.3237 - val_loss: 0.1311\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2777 - val_loss: 0.1006\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.2317 - val_loss: 0.0757\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1867 - val_loss: 0.0602\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1446 - val_loss: 0.0597\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1084 - val_loss: 0.0815\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0825 - val_loss: 0.1322\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0721 - val_loss: 0.2091\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0794 - val_loss: 0.2892\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0976 - val_loss: 0.3396\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1125 - val_loss: 0.3447\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.1148 - val_loss: 0.3122\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.1053 - val_loss: 0.2598\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0906 - val_loss: 0.2038\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0768 - val_loss: 0.1547\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0674 - val_loss: 0.1166\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0632 - val_loss: 0.0896\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0630 - val_loss: 0.0718\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0650 - val_loss: 0.0607\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0677 - val_loss: 0.0542\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0699 - val_loss: 0.0508\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0709 - val_loss: 0.0498\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0705 - val_loss: 0.0505\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0688 - val_loss: 0.0530\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0662 - val_loss: 0.0573\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0629 - val_loss: 0.0635\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0595 - val_loss: 0.0719\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0565 - val_loss: 0.0821\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0542 - val_loss: 0.0938\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0529 - val_loss: 0.1060\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0524 - val_loss: 0.1177\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0526 - val_loss: 0.1275\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0531 - val_loss: 0.1343\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0535 - val_loss: 0.1373\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0534 - val_loss: 0.1364\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0527 - val_loss: 0.1320\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0515 - val_loss: 0.1252\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0501 - val_loss: 0.1169\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0487 - val_loss: 0.1083\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0475 - val_loss: 0.1001\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0467 - val_loss: 0.0928\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0463 - val_loss: 0.0868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
     ]
    }
   ],
   "source": [
    "model_lstm=Sequential([\n",
    "    LSTM(200, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False),\n",
    "    Dense(units=future_steps, activation='linear')\n",
    "])\n",
    "model_lstm.compile(optimizer='adam', loss='mse')\n",
    "history_lstm=model_lstm.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred_lstm=model_lstm.predict(X_test)\n",
    "y_pred_lstm_inverse=scaler.inverse_transform(y_pred_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e994f8-0179-4a47-af00-082af5cace00",
   "metadata": {},
   "source": [
    "#Evaluation_of_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0c530503-59fd-4c49-b0b5-14008e714be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_tkan=mean_squared_error(y_test_inverse, y_pred_tkan_inverse)\n",
    "r2_tkan=r2_score(y_test_inverse, y_pred_tkan_inverse)\n",
    "\n",
    "mse_lstm=mean_squared_error(y_test_inverse, y_pred_lstm_inverse)\n",
    "r2_lstm=r2_score(y_test_inverse, y_pred_lstm_inverse)\n",
    "\n",
    "results.append({\n",
    "    'future_steps':future_steps,\n",
    "    'R^2_TKAN':r2_tkan,\n",
    "    'R^2_LSTM':r2_lstm\n",
    "})\n",
    "results_df=pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40d59a62-b898-432a-8ea1-47461e833df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'future_steps': 5,\n",
       "  'R^2_TKAN': -37.755708830194145,\n",
       "  'R^2_LSTM': -25.95765195475434}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
